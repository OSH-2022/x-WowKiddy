# 调研报告


## 小组成员
-   柯景瀚
-   吴骏  
-   丁程
-   余丰
-   王腾岳
-   wkdwy(蜗壳动物园)荣誉出品


## 目录
- [调研报告](#调研报告)
	- [小组成员](#小组成员)
	- [目录](#目录)
	- [项目概述](#项目概述)
	- [项目背景](#项目背景)
		- [日志文件系统](###日志型文件系统)
		- [APFS](###APFS)
		- [Juicefs](###Juicefs)
		- [数据一致性问题](###数据一致性问题)
		  - [CRDT](####CRDT理论)
		  - [Paxos](####Paxos算法)
		- [分布式文件系统的高性能问题](###分布式文件系统中的高性能问题)
			- [使用缓存](####使用缓存)
				- [为什么要解决缓存的问题](#####为什么要解决缓存的问题)
			- [数据追加型增删改](####数据追加型增删改)
				- [哈希存储引擎](#####哈希存储引擎)
					- [常见的索引](######常见的索引)
	- [立项依据](##立项依据)
	- [前瞻性/重要性分析](##前瞻性/重要性分析)
		- [使用cache的必要性](###使用cache的必要性)
			- [用户cache](####用户cache)
			- [索引服务器cache](####索引服务器cache)
	- [相关工作](##相关工作)
		- [Juicsfs](###Juicefs)
			- [核心特性](####核心特性)
			- [技术架构](####技术架构)
			- [计算与存储分离](####计算和存储分离)
		- [x-DisGraFs](###x-DisGraFS)
			- [部署问题与难点](####部署问题与难点)
		- [Lua](###Lua)  
	- [参考文献](##参考文献)

## 项目概述

在2021年OSH项目[x-DisGraFS](https://github.com/OSH-2021/x-DisGraFS) 的基础上，根据文件自然属性的逻辑关联，完善分布式文件系统的缓存机制，同时在索引和写入读取上进行优化，并且保证部署的稳定性和便捷性，以期望提高分布式文件系统的性能。

## 项目背景

### 日志型文件系统

**日志文件系统**（英语：Journaling file system）是一种文件系统。在发生变化时，它先把相关的信息写入一个被称为**日志**的区域，然后再把变化写入主文件系统。在文件系统发生故障（如内核崩溃或突然停电）时，日志文件系统更容易保持一致性，并且可以较快恢复。

对文件系统进行修改时，需要进行很多操作。这些操作可能中途被打断，也就是说，这些操作不是“不可中断”(atomic)的。如果操作被打断，就可能造成文件系统出现不一致的状态。

例如：删除文件时，先要从目录树中移除文件的标示，然后收回文件占用的空间。如果在这两步之间操作被打断，文件占用的空间就无法收回。文件系统认为它是被占用的，但实际上目录树中已经找不到使用它的文件了。

在非日志文件系统中，要检查并修复类似的错误就必须对整个文件系统的数据结构进行检查。一般在挂载文件系统前，操作系统会检查它上次是否被成功卸载，如果没有，就会对其进行检查。如果文件系统很大或者**I/O**有限，这个操作可能会花费很长时间。

为了避免这样的问题，日志文件系统分配了一个称为日志（journal）的区域来提前记录要对文件系统做的更改。在崩溃后，只要读取日志重新执行未完成的操作，文件系统就可以恢复一致。这种恢复是原子的，因为只存在几种情况：

-   不需要重新执行：这个事务被标记为已经完成
-   成功重新执行：根据日志，这个事务被重新执行
-   无法重新执行：这个事务会被撤销，就如同这个事务从来没有发生过
-   日志本身不完整：事务还没有被完全写入日志，它会被简单忽略

### APFS 

apfs是apple公司推出的取代HFS+的文件系统，它的性能优秀，并且采用了一种日志的机制来增改文件，作为重要的Crash protection的手段，它为了避免由系统崩溃而引起的元数据的损坏，它并不是在覆盖现有元数据的情况下进行数据的删改，而是编写日志记录，然后将指针指向新记录，释放旧记录，这样就避免了由于更新过程中发生的崩溃而导致的包含部分旧数据和部分新数据的损坏记录。它的这种方法同时还避免了不得不两次写入变化，就像HFS+一样，变化首先被写入日志，然后再被写入目录文件。

### Juicefs

JuiceFS 是一款面向云环境设计的高性能共享文件系统，在 AGPL v3.0 开源协议下发布。提供完备的 POSIX 兼容性，可将海量低价的云存储作为本地磁盘使用，亦可同时被多台主机同时挂载读写。使用 JuiceFS 存储数据，数据本身会被持久化在对象存储（例如，Amazon S3），而数据所对应的元数据可以根据场景需要被持久化在 Redis、MySQL、SQLite 等多种数据库中。但是对于这个文件系统来说，尽管JuiceFS拥有很多的优点，而且很努力的去逼近本地存储的性能，但网络延迟，IOPS以及对象存储自身的限制，在写方面，依然和本地存储(SSD)有接近百倍的性能差距，这对于很多OLTP数据库是有比较大的影响的，但对读的优化，使得其对于OLAP等以读多的引擎则帮助巨大。详细信息见[juicsfs](https://github.com/juicedata/juicefs)。

### 数据一致性问题

#### CRDT理论
​	CRDT，全称无冲突复制数据类型(Conflict-free Replicated Data Type)，在具体阐述之前，先简要介绍一下分布式系统的CAP理论。

CRDT理论主要包括以下几个方面：

​	强一致性(Consistency)： 即在分布式系统中的同一数据多副本情形下， 对千数据的更新操作体现出的效果与只有单份数据是一样的。

​	可用性(Availability)： 客户端在任何时刻对大规模数据系统的读／写操作都应该保证在限定延时内完成。

​	分区容忍性(Partition Tolerance)： 在大规模分布式数据系统中， 网络分区现象， 即分区间的机器无法进行网络通信的情况是必然会发生的， 所以系统应该能够在这种情况下仍然继续工作。

​	CAP 最初是由Eric Brewer于1999 年首先提出的， 他同时证明了：**对于一个大规模分布式数据系统来说， CAP 三要素不可兼得**， 同一个系统至多只能实现其中的两个， 而必须放宽第3 个要素来保证其他两个要素被满足。
关于CRDT的详细介绍见![CRDT调研报告](docs/CRDT调研报告.md)
#### Paxos算法
​	Paxos算法是Lamport提出的一种基于消息传递的分布式一致性算法，使其获得2013年图灵奖。Paxos由Lamport于1998年在《The Part-Time Parliament》论文中首次公开，最初的描述使用希腊的一个小岛Paxos作为比喻，描述了Paxos小岛中通过决议的流程，并以此命名这个算法，但是这个描述理解起来比较有挑战性。后来在2001年，Lamport觉得同行不能理解他的幽默感，于是重新发表了朴实的算法描述版本《Paxos Made Simple》。自Paxos问世以来就持续垄断了分布式一致性算法，Paxos这个名词几乎等同于分布式一致性。Google的很多大型分布式系统都采用了Paxos算法来解决分布式一致性问题，如Chubby、Megastore以及Spanner等。开源的ZooKeeper，以及MySQL 5.7推出的用来取代传统的主从复制的MySQL Group Replication等纷纷采用Paxos算法解决分布式一致性问题。
​	算法具体描述参见Lamport的论文《Paxos Made Simple》。其中一个比较完善的实现是腾讯的一个工程：[phxpaxos](https://github.com/Tencent/phxpaxos)
PhxPaxos是腾讯公司微信后台团队自主研发的一套基于Paxos协议的多机状态拷贝类库。它以库函数的方式嵌入到开发者的代码当中， 使得一些单机状态服务可以扩展到多机器，从而获得强一致性的多副本以及自动容灾的特性。 这个类库在微信服务里面经过一系列的工程验证，并且腾讯方面对它进行过大量的恶劣环境下的测试，使其在一致性的保证上更为健壮。关于该部分的详细介绍见仓库内报告：[[分布式文件系统的数据一致性]]。

### 分布式文件系统中的高性能问题

对一个分布式文件系统而言，性能是非常关键的衡量标准，有一些特性是一个分布式文件系统必须要满足的，否则就无法有竞争力。主要如下：

-   应该符合 POSIX 的文件接口标准，使该系统易于使用，同时对于用户的遗留系统也无需改造；
-   对用户透明，能够像使用本地文件系统那样直接使用；
-   持久化，保证数据不会丢失；
-   具有伸缩性，当数据压力逐渐增长时能顺利扩容；
-   具有可靠的安全机制，保证数据安全；
-   数据一致性，只要文件内容不发生变化，什么时候去读，得到的内容应该都是一样的。

除此之外，还有些特性是分布式加分项，具体如下：

-   支持的空间越大越好；
-   支持的并发访问请求越多越好；
-   性能越快越好；
-   硬件资源的利用率越高越合理越好。

#### 使用缓存

##### 为什么要解决缓存的问题
文件系统中可以使用缓存来实现性能的提升，对于一个由对象存储和数据库组合驱动的文件系统，缓存是本地客户端与远端服务之间高效交互的重要纽带。读写的数据可以提前或者异步载入缓存，再由客户端在后台与远端服务交互执行异步上传或预取数据。相比直接与远端服务交互，采用缓存技术可以大大降低存储操作的延时并提高数据吞吐量。

在这里Juicsfs实现了比较高效的缓存机制。详细内容见[juicsfs cache_management](https://juicefs.com/docs/zh/community/cache_management)。

#### 数据追加型增删改

##### 哈希存储引擎
哈希存储的基本思想是以关键字Key为自变量，通过一定的函数关系(散列函数或哈希函数），计算出对应函数值（哈希地址），以这个值作为数据元素的地址，并将数据元素存入到相应地址的存储单元中。查找时再根据要查找的关键字采用同样的函数计算出哈希地址，然后直接到相应的存储单元中去取要找的数据元素。代表性的使用方包括Redis，Memcache，以及存储系统Bitcask等。

基于内存中的Hash,支持随机的增删改查，读写的时间复杂度O(1)。但无法支持顺序读写(指典型Hash，不包括如Redis的基于跳表的ZSet的其它功能),在不需要有序遍历时，性能最优。

基于哈希表结构的键值存储系统，仅支持追加写操作，即所有的写操作只追加而不修改老的数据，同一个时刻，只有一个活跃的新文件。

主要思想是：
1.内存中采用基于哈希表的索引结构，即hash表存放的是数据在磁盘上的位置索引，磁盘上存放的是主键和value的实际内容。

2.定期合并，定期将旧的数据或者删除操作进行合并，保留最新的数据。

3.掉电恢复，在磁盘上保留一份索引记录，在定期合并的时候产生这份索引记录，当磁盘掉电的时候直接通过这个索引记录到内存中重建即可。

存在的问题：索引的长度远小于数据的长度，这样内存存放的索引越多，磁盘存放的数据就越多。
###### 常见的索引
首先，索引的出现就是为了提高数据查询的效率，像书的目录一样。常见的有三种：哈希表、有序数组和搜索树。

`哈希表`是一种以哈希函数完成键 - 值（key-value）存储数据的结构。
于是：
-   如何解决哈希冲突是一门艺术。
-   适用于等值查询，而不适用于范围查询。

`有序数组`，按照某一信息的有序性进行存储，范围查询的效率也很不错（比如可以使用二分法），仅看查询，它估计是最好的数据结构，但是更新数据很麻烦，所以只适用于静态存储引擎（只存储不再修改的数据）。

`搜索树`，典型如平衡二叉树，查询和更新的时间复杂度均为O(log(N))，效率在搜索树中是最高的，但是一般都不会使用，原因是：索引不止存在内存中，还要写到磁盘上。比如如果有100 万节点，树高20，一次查询可能需要访问 20 个数据块，而从磁盘随机读一个数据块需要 一定的寻址时间。所以一般都会使用N叉树（N取决于数据块大小），让查询过程中尽可能少地访问磁盘。典型如B+树、LSM树。

具体可参考[redis中的hash](http://www.redis.cn/commands.html#hash)，[bitcask中的hash](https://juejin.cn/post/6844903774377476109)。

## 立项依据

如上所言，分布式文件系统在现在有着越来越多的应用范围，它的性能逐渐成为一个非常重要的指标，对于现有的分布式文件系统来说，如juicsfs等，其读写性能仍然未能达到我们所期望的高性能文件系统所应该有的标准。在这里我们决定从几个不同的方向优化打造一个高性能的文件系统——缓存服务器和地址的哈希映射等来优化2021年的OSH项目[x-DisGraFS](https://github.com/OSH-2021/x-DisGraFS)。利用它实现的一个对文件内容的打标搜索，提高原有文件系统的检索与读取性能，同时满足不同节点数据的一致性，打造一个高性能的分布式文件系统。

## 前瞻性/重要性分析

### 使用cache的必要性
#### 用户cache
& 案例一，假设用户在使用关键词“雪”进行搜索后，界面将展示所有与“雪”有关的文件，用户打开其中的文件A，发现不是自己想用的，于是又打开文件B，也许还不是。打开文件A时，在DGFS中会进行：将消息传达服务器——JFS响应，在分布式存储集群中找到文件——请求节点得到文件，如果文件B不在用户JFS的cache里，那么打开文件B时也是同样的流程，这样的存取延迟在用户很少、文件很少时影响不大，但如果大量用户、文件接入，同时进行打开操作，不仅使服务器负载加大，更重要的是会带来大量的访存操作，况且网络读写的速度还是远慢于内存的读写，存取延迟也许让用户无法接受。

& 案例二，我们设想WowKiddy未来可以便利地参与构建用于AI模型的训练数据集，并与筛选预处理平台或训练平台进行对接。一个高精度AI模型离不开大量的优质数据集，这些数据集往往由标注结果文件和海量的图片组成。数据集都放在远端的对象存储集群中，当运行模型训练任务时就需要访问远程存储来获取数据集，带来较高的网络 I/O开销，也会造成数据集管理不便的问题。

在DGFS中，文件与文件的逻辑关系更清晰、紧密，若WowKiddy基于更强的逻辑关系布置cache，能有效提升访存命中率。这里的工作大致应该分为两个部分：

1.juicefs的默认缓存机制是顺序读取一个block作为用户的缓存，用以提高下次搜索的命中率，由于我们现在得到了文件的自然属性，那么我们可以将这个block通过某种方法替换成相同标签的block，这样对于cache的命中率会大幅度提高。

2.当同一个tag的文件内容过大时，我们不应该传入到本机的cache当中，这样会大大占用用户的网络带宽，这里我们可以将一个服务器节点抽象成一个虚拟的cache，不是作为本地的cache。比如我的存储集群在北京，而我在合肥，那么当我想去读取某个文件的时候，它可以实现将相同tag的文件发送到我的同城服务器中，这样当我再次去访问相同tag的文件的时候，就可以直接从同城服务器里拿到我想要的数据，这样的速度较于还是从北京拿数据要快得多。这样也没有占用用户本机的网络带宽，可以带给用户更好的体验效果。

另外，可以基于cache添加一个新功能——支持文件预览，比如将鼠标放在某jpg文件泡上，该jpg会自动展示给用户，比如将鼠标放在视频文件上，可以进行小窗口多倍数预览等。
#### 索引服务器cache
&案例，在DGFS中，用户每次发送搜索请求时，索引服务器会根据关键字创建搜索语句，然后进入neo4j进行搜索，再将相关标签的所有文件通过图和列表方式返回网页端。第一，如果用户在第一次、第三次、第五次搜索的都是同一个tag，那么都进行这么一个过程，显然会造成不必要的计算开销和能源浪费；第二，每次那么如果大量用户接入，文件也很多时，如果大部分人常搜索部分tag，那么获取搜索结果信息也会有明显的延迟。
若WowKiddy增设索引服务器的cache呢？

## 相关工作

### Juicefs
JuiceFS 是一款面向云环境设计的高性能共享文件系统，在 AGPL v3.0 开源协议下发布。提供完备的 [POSIX](https://en.wikipedia.org/wiki/POSIX) 兼容性，可将海量低价的云存储作为本地磁盘使用，亦可同时被多台主机同时挂载读写。

使用 JuiceFS 存储数据，数据本身会被持久化在对象存储（例如，Amazon S3），而数据所对应的元数据可以根据场景需要被持久化在 Redis、MySQL、SQLite 等多种数据库中。

JuiceFS 提供了丰富的 API，可以在不修改代码的前提下无缝对接已投入生产的大数据、机器学习、人工智能等应用平台，为其提供海量、弹性、低价的高性能存储。

#### 核心特性
1.  **POSIX 兼容**：像本地文件系统一样使用，无缝对接已有应用，无业务侵入性；
2.  **HDFS 兼容**：完整兼容 HDFS API，是大数据集群实现存储计算分离架构的理想存储选择；
3.  **S3 兼容**：提供 S3 Gateway 实现 S3 协议兼容的访问接口；
4.  **云原生**：通过 Kubernetes CSI Driver 可以很便捷地在 Kubernetes 中使用 JuiceFS；
5.  **多端共享**：同一文件系统可在上千台服务器同时挂载，高性能并发读写，共享数据；
6.  **强一致性**：确认的修改会在所有挂载了同一文件系统的服务器上立即可见，保证强一致性；
7.  **强悍性能**：毫秒级的延迟，近乎无限的吞吐量（取决于对象存储规模）；
8.  **数据安全**：支持传输中加密（encryption in transit）以及静态加密（encryption at rest）；
9.  **文件锁**：支持 BSD 锁（flock）及 POSIX 锁（fcntl）；
10.  **数据压缩**：支持使用 [LZ4](https://lz4.github.io/lz4) 或 [Zstandard](https://facebook.github.io/zstd) 压缩数据，节省存储空间；

#### 技术架构
![image](https://juicefs.com/docs/zh/assets/images/juicefs-arch-new-a58938733d246f30089d5302dd268c29.png)

#### 计算和存储分离
在分布式架构发展过程中，计算和存储融合的架构缺点也在逐渐暴露：
-   机器的浪费：业务是计算先达到瓶颈的，还是存储先达到瓶颈的。这两种情况往往是不一样的，往往时间点也是不一样的。在架构里就存在一定的浪费。如果说计算不够，也是加一台机器；存储不够，还是加一台机器。所以这里就会存在很多浪费。
-   机器配比需要频繁更新：一般来说在一个公司内机器的配型比较固定比如提供好几种多少核，多少内存，多少存储空间等等。但是由于业务在不断的发展，那么我们的机器配型也需要不断的更新。
-   扩展不容易：如果我们存储不够了通常需要扩展，计算和存储耦合的模式下如果扩展就需要存在迁移大量数据。

### x-DisGraFS

在分布式机群的规模上，图文件系统能够实现所管理的信息规模的扩大与各类资源的均衡分配，从而在超出人类记忆能力的信息规模上体现出图文件系统相对于传统树形结构的优越性。通过主机（Master）对从机（Slave）的存储空间以及算力的合理调度以及在主机的指导下用户与从机之间的直接对接，x-DisGraFs的项目实现了一个高效的、用户友好的、高可扩展性的分布式图文件系统，以进一步拓展图文件系统在未来应用中的可能性。
#### 部署问题与难点
dfs的代码中对于服务器等ip地址依赖较为严重，进行部署的过程中需要修改部分代码，对于用户的部署十分不友好（*对比Juicefs*）。同时他们的部署文档不够详细且不够用户友好，同时对于各种错误没有详细的说明与解决方案。对于一个成熟的开源项目来说，特别是文件系统这种更接近于大众的产品，一个更加友好的部署策略和一个多平台可扩展的代码实现时非常重要的。这里我们完成了一个详细的部署文档，同时萌生了自动化部署的想法。

### Lua

**Lua**，葡萄牙语“月亮”，是一个简洁、轻量、可扩展的[脚本语言](https://zh.wikipedia.org/wiki/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80 "脚本语言")。Lua有着相对简单的[C](https://zh.wikipedia.org/wiki/C%E8%AF%AD%E8%A8%80 "C语言") [API](https://zh.wikipedia.org/wiki/API "API")而很容易嵌入应用中。很多应用程序使用Lua作为自己的嵌入式脚本语言，以此来实现可配置性、可扩展性。

Lua是一种轻量语言，它的官方版本只包括一个精简的核心和最基本的库。这使得Lua体积小、启动速度快。它用ANSI C语言编写，并以源代码形式开放，编译后的完整参考[解释器](https://zh.wikipedia.org/wiki/%E8%A7%A3%E9%87%8A%E5%99%A8 "解释器")只有大约247kB，到5.4.3版本，该体积变成283kB（Linux,amd64），依然非常小巧，可以很方便的嵌入别的程序里。和许多“大而全”的语言不一样，网络通信、图形界面等都没有默认提供。但是Lua可以很容易地被扩展：由宿主语言（通常是C或C++）提供这些功能，Lua可以使用它们，就像是本来就内置的功能一样。事实上，现在已经有很多成熟的扩展模块可供选用。

Lua是一个[动态类型](https://zh.wikipedia.org/wiki/%E5%8A%A8%E6%80%81%E7%B1%BB%E5%9E%8B "动态类型")语言，支持增量式[垃圾收集](https://zh.wikipedia.org/wiki/%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6_(%E8%A8%88%E7%AE%97%E6%A9%9F%E7%A7%91%E5%AD%B8) "垃圾回收 (计算机科学)")策略。有内建的，与操作系统无关的[协作式多线程](https://zh.wikipedia.org/wiki/%E5%8D%8F%E7%A8%8B "协程")支持。Lua原生支持的数据类型很少，只提供了数值（默认是[双精度浮点数](https://zh.wikipedia.org/wiki/%E6%B5%AE%E9%BB%9E%E6%95%B8 "浮点数")，可配置）、布尔量、[字符串](https://zh.wikipedia.org/wiki/%E5%AD%97%E7%AC%A6%E4%B8%B2 "字符串")、表格、[函数](https://zh.wikipedia.org/wiki/%E5%AD%90%E7%A8%8B%E5%BA%8F "子程序")、[线程](https://zh.wikipedia.org/wiki/%E7%BA%BF%E7%A8%8B "线程")以及用户自定义数据这几种。但是其处理表和字符串的效率非常之高，加上元表的支持，开发者可以高效的模拟出需要的复杂数据类型（比如集合、数组等）。


## 参考文献

[日志文件系统wiki](https://zh.wikipedia.org/zh-cn/%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F)
[redis中的hash](http://www.redis.cn/commands.html#hash)
[bitcask中的hash](https://juejin.cn/post/6844903774377476109)
[juicsfs community](https://juicefs.com/docs/zh/community)
[phxpaxos](https://github.com/Tencent/phxpaxos)
[Lua](https://en.wikipedia.org/wiki/Lua_(programming_language))
